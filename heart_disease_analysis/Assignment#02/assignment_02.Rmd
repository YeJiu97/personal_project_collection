---
title: "Building a Decision Tree Predictive Model"
author: "Wangjun SHEN"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

The goal of this assignment is to create a decision tree model that predicts heart disease. The quality of work will be improved by enhancing the presentation of results. To achieve this, more visually appealing representations, such as tables and graphics, will be used instead of code snippets.

Machine learning algorithms have become increasingly popular in the field of heart disease detection due to their potential to improve accuracy and enable early diagnosis. This assignment aims to explore the dataset and extract relevant features for analysis, while considering feedback on the selected features to ensure optimal predictive power. The data exploration process will be conducted using R and RStudio, and will involve the use of descriptive statistics and visualizations such as value distributions, histograms, bar plots, and box plots. These techniques will help us gain insights into the dataset and investigate correlations between important variables. Correlation plots or correlograms will also be used to analyze these relationships. Next, decision tree models will be built using R, taking into account parameters such as maximum depth, minimum number of samples for splitting, and complexity. Multiple models with different parameter values will be fit and their performance will be compared using metrics such as accuracy, precision, recall, F-score, and AUC.

In conclusion, this assignment aims to develop a decision tree model for heart disease prediction while addressing previous feedback on result presentation. The assignment requirements will be followed and improvements will be incorporated to deliver a comprehensive analysis of heart disease detection using decision trees.



# Related Work

To be Continuous for this part


# Data exploration

## Explain the features you decided to extract.

The same feature set that was extracted in Assignment 1 will be used to predict heart disease. Based on feedback received, the background section was the main area of focus and no specific issues were raised with the selected feature set. Therefore, the previously chosen feature set will be maintained as it includes relevant variables associated with heart disease. These features encompass demographic information such as age, sex, and chest pain type, as well as physiological indicators like blood pressure, cholesterol levels, and maximum heart rate.

## Provide descriptive statistics (using tables and figures) of your feature set


Import data set:

```{r}
# Read the CSV file into a data frame
heart_data <- read.csv("heart_features_selected.csv")

sapply(heart_data, class)
```

When examining a dataset, it's crucial to verify for any absent values. This is because absent values can influence the precision and credibility of the analysis, resulting in prejudiced outcomes and less efficient models. Spotting and resolving absent values can enhance the quality of the analysis.

```{r}
# Identify missing values represented as "nan", "none", or "null" (case-insensitive)
missing_values <- c("nan", "none", "null", "NA", "N/A")
missing_count <- sapply(heart_data, function(x) sum(toupper(x) %in% toupper(missing_values), na.rm = TRUE))

# Create a table to display the missing value count
missing_table <- data.frame(Feature = names(missing_count), Count = missing_count)
print(missing_table)

```

The majority of features in the dataset are complete, except for the restwm feature which contains 7 missing values. It is important to further investigate these missing values in order to maintain the accuracy and completeness of the data.

Drop those missing values:

```{r}

# Remove rows with missing values in restwm column
heart_data <- heart_data[heart_data$restwm != "none", ]

# Verify the changes
print(head(heart_data))

```

The majority of features in the dataset are complete, with the exception of the restwm feature, which has 7 missing values. These values will be removed directly, as the dataset is sufficiently large, and their removal will have no impact.

Drop id variable, and then convert sex, cp, exang, restwm and target into categories/factor type:

```{r}

# Drop the "id" variable
heart_data <- heart_data[, -which(names(heart_data) == "id")]

# Convert variables to factor type
convert_vars <- c("sex", "cp", "exang", "restwm", "target")
heart_data[convert_vars] <- lapply(heart_data[convert_vars], as.factor)

str(heart_data)
```

Now create two sub data set for categories features and numeric features:

```{r}

# Subset categorical variables
categories_df <- heart_data[, sapply(heart_data, is.factor)]

# Subset numeric variables
numeric_df <- heart_data[, sapply(heart_data, is.numeric)]
```

To begin, an examination will be made of how the categories are distributed:

```{R}
# Descriptive statistics for categorical variables
summary(categories_df)

# Value distributions
table_data <- lapply(categories_df, table)
print(table_data)

# Increase plot size
par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))  # Set the layout and margin

for (i in 1:ncol(categories_df)) {
  barplot(table_data[[i]], main = names(table_data)[i], xlab = "", ylab = "Frequency", las = 2, cex.axis = 1.5)  # Adjust cex.axis for larger axis labels
}

# Reset the layout and margin
par(mfrow = c(1, 1), mar = c(5, 4, 4, 2) + 0.1)



```

This document contains data on various factors related to heart disease. The sex variable has 309 samples for females and 709 for males. The cp variable has four categories, with typical angina being the most common at 493 occurrences. The exang variable has two categories, with 677 instances of FALSE and 341 instances of TRUE. The restwm variable has three categories, with moderate or severe being the most frequent at 544 occurrences. The target variable has two categories, with 523 cases of disease and 495 cases of no disease.


Then explore Numeric Features:

```{r}

custom_summary <- function(data) {
  # Calculate basic summary statistics
  summary_stats <- summary(data)
  
  # Calculate additional statistics
  n <- nrow(data)
  missing_values <- sum(is.na(data))
  unique_values <- sapply(data, function(x) length(unique(x)))
  skewness <- sapply(data, function(x) psych::skew(x, na.rm = TRUE))
  kurtosis <- sapply(data, function(x) psych::kurtosi(x, na.rm = TRUE))
  
  # Create a new summary dataframe
  summary_df <- data.frame(
    Min = summary_stats[1, ],
    Q1 = summary_stats[2, ],
    Median = summary_stats[3, ],
    Mean = summary_stats[4, ],
    Q3 = summary_stats[5, ],
    Max = summary_stats[6, ],
    Missing = missing_values,
    Unique = unique_values,
    Skewness = skewness,
    Kurtosis = kurtosis
  )
  
  # Return the summary dataframe
  return(summary_df)
}

# Call the custom summary function on your numeric dataframe
summary_result <- custom_summary(numeric_df)

summary_result


# Value distributions
for (i in 1:ncol(numeric_df)) {
  cat("Variable:", names(numeric_df)[i], "\n")
  cat(table(numeric_df[, i]), "\n\n")
}

# Histograms
par(mfrow = c(2, 2))  # Set the layout for multiple plots

for (i in 1:ncol(numeric_df)) {
  hist(numeric_df[, i], main = names(numeric_df)[i], xlab = "Value", ylab = "Frequency")
}

# Box plots
par(mfrow = c(1, 1))  # Reset the layout for plots
boxplot(numeric_df, main = "Numeric Variables", xlab = "Variable", ylab = "Value")


```

The age variable ranges from 29 to 77 years, with a median age of 56 years and a mean age of 54.45 years. The majority of individuals fall between the ages of 48 to 61 years. The maximum heart rate achieved (thalach) ranges from 71 to 202 beats per minute (bpm). The median heart rate is 152 bpm, with a mean heart rate of 149.2 bpm. Most individuals have a heart rate between 132 and 166 bpm. The ST depression induced by exercise relative to rest (oldpeak) ranges from 0 to 6.2. The median value is 0.8, indicating a mild ST depression on average. The mean value is 1.075, indicating a slightly higher overall ST depression. The number of major vessels colored by fluoroscopy (major_vessels) ranges from 0 to 4. Most individuals have 0 major vessels colored, with a median value of 0 and a mean value of 0.7593. However, there is some variability, as some individuals have up to 4 major vessels colored.

The above figure shows the visualization results of the distribution of numeric features, which is convenient for intuitive observation.

Box plots provide a visual representation of the data distribution, including any potential outliers, and can be used to identify points located outside the whiskers or outside the box. The age data does not contain any apparent outliers, as both the minimum and maximum values fall within a reasonable range for human age. However, for thalach, there are some values that exceed both the upper quartile (Q3) and the maximum value. These values could potentially be considered outliers. No extreme or outlier values are present for the ST depression caused by exercise relative to rest (oldpeak) or the number of major vessels stained by fluoroscopy (major_vessels).


```{r}

# Detect outliers in numeric variables
outliers <- sapply(numeric_df, function(x) {
  lower <- quantile(x, probs = 0.25) - 1.5 * IQR(x)
  upper <- quantile(x, probs = 0.75) + 1.5 * IQR(x)
  x[x < lower | x > upper]
})

# Create a combined plot for outlier visualization
par(mfrow = c(2, 2))  # Set the layout for multiple plots

# Plot boxplots with outliers highlighted
for (i in 1:ncol(numeric_df)) {
  boxplot(numeric_df[, i], main = names(numeric_df)[i], xlab = "Variable", ylab = "Value", outline = !is.null(outliers[[i]]))
}

# Reset the layout for plots
par(mfrow = c(1, 1))



```

Each numerical variable will then be examined for any values that fall outside the upper and lower limits, which are considered outliers and may indicate the presence of extreme data values.


```{r}

# Identify rows with outliers in numeric variables
outlier_rows <- apply(sapply(numeric_df, function(x) {
  lower <- quantile(x, probs = 0.25) - 1.5 * IQR(x)
  upper <- quantile(x, probs = 0.75) + 1.5 * IQR(x)
  x < lower | x > upper
}), 1, any)

# Remove rows with outliers from heart_data
heart_data <- heart_data[!outlier_rows, ]

# Verify the updated dataset
str(heart_data)

```

## The Correlation Between Variables

For features in categories_df:

```{r}

# Convert categorical variables to numeric representation
numeric_categories_df <- sapply(categories_df, as.numeric)

# Compute the correlation matrix
cor_matrix <- cor(numeric_categories_df)

# Display the correlation values
cor_matrix


```

```{r}
library(corrplot)

# Convert categorical variables to numeric representation
numeric_categories_df <- sapply(categories_df, as.numeric)

# Compute the correlation matrix
cor_matrix <- cor(numeric_categories_df)

# Create a correlation matrix plot with values displayed in squares
corrplot(cor_matrix, method = "square", type = "upper", addCoef.col = "black")

```

Several correlation coefficients were observed between different variables and the likelihood of heart attack. Notably, a positive correlation of 0.27 was found between sex and target, suggesting a potential association between gender and the probability of heart attack. Additionally, a moderate positive correlation of 0.41 was observed between cp and target, indicating a potential link between chest pain type and the likelihood of heart attack. Moreover, a moderate positive correlation of 0.43 was present between exang and target, implying a possible connection between exercise-induced angina and the probability of heart attack. Finally, a strong negative correlation of -0.52 was observed between restwm and target, suggesting a significant association between abnormal resting electrocardiogram and the probability of heart attack.


```{r}

cor_matrix <- cor(numeric_df)

library(corrplot)
corrplot(cor_matrix, method = "square", type = "upper", addCoef.col = "black")

cor_matrix

```

Now import the data set:

```{r}
write.csv(heart_data, file = "features_prepare_for_modelling.csv", row.names = FALSE)
```


# Building Decision Tree Models

Using 70% of the data for training provides ample samples to learn the parameters and features of the model, which enables the model to capture patterns and correlations in the data more effectively, thereby improving the model's generalization ability. Using 30% of the data for testing can evaluate the performance of the trained model. This segment of the data did not participate in the training process, so it can be used to verify the model's performance on unseen data, providing an estimate of the model's generalization ability and judging its effectiveness in practical applications. Meanwhile, using less testing data can better check whether the model is overfitting, reducing the risk of overfitting while improving the accuracy of the model. In machine learning, the 70% training and 30% testing ratio is widely accepted and used in many research and practice as it is believed to provide reasonable results in most cases.

```{r}
# Set the seed for reproducibility
set.seed(123)

# Split the data into training and testing sets
train_indices <- sample(1:nrow(heart_data), 0.7*nrow(heart_data))
train_data <- heart_data[train_indices, ]
test_data <- heart_data[-train_indices, ]
```

Demonstrates data partitioning using a 70% training and 30% testing ratio:

```{r}
library(rpart)

# Fit the decision tree model
tree_model_01 <- rpart(target ~ ., data = train_data, method = "class")

# Print the details of the decision tree model
print(tree_model_01)
```

Visualization the decision tree:

```{r}

library(rpart.plot)

# Increase the size and resolution of the output image
png(file = "decision_tree_01.png", width = 1200, height = 800, res = 300)

# Plot the decision tree
rpart.plot(tree_model_01)

# Save and close the image
dev.off()

```

In rpart, the complexity parameter (cp) is a hyperparameter that governs the complexity of the decision tree. It decides whether a split should be attempted or not, based on whether it can improve the overall fit by a factor. In cases where anova split is used, the overall R-squared value must increase cp at each step. The primary role of this parameter is to prune unnecessary splits and save computation time. The default value of cp is 0.05, resulting in an incomplete decision tree by default.


```{r}

# Fit the decision tree model
tree_model_02 <- rpart(target ~ ., data = train_data, method = "class",  cp = 0)

# Print the details of the decision tree model
print(tree_model_02)

```

```{r}
# Increase the size and resolution of the output image
png(file = "decision_tree_02.png", width = 1200, height = 800, res = 300)

# Plot the decision tree
rpart.plot(tree_model_02)

# Save and close the image
dev.off()

```


```{r}
# Fit the decision tree model
tree_model_03 <- rpart(target ~ ., data = train_data, method = "class",  minsplit = 50)

# Print the details of the decision tree model
print(tree_model_03)


# Increase the size and resolution of the output image
png(file = "decision_tree_03.png", width = 1200, height = 800, res = 300)

# Plot the decision tree
rpart.plot(tree_model_03)

# Save and close the image
dev.off()

```

The rpart function's maxdepth parameter influences how deep a decision tree can be. Smaller values result in simpler trees with fewer branches and nodes, which makes them easier to interpret and reduces computational complexity. By modifying maxdepth, a trade-off between model complexity and performance can be achieved. Experimenting with different values can help identify the optimal depth for a given dataset and problem.


```{r}
# Fit the decision tree model
tree_model_04 <- rpart(target ~ ., data = train_data, method = "class",  maxdepth = 4)

# Print the details of the decision tree model
print(tree_model_04)


# Increase the size and resolution of the output image
png(file = "decision_tree_04.png", width = 1200, height = 800, res = 300)

# Plot the decision tree
rpart.plot(tree_model_04)

# Save and close the image
dev.off()

```

```{r}
# Calculate accuracy for tree_model_01
predictions_01 <- predict(tree_model_01, newdata = test_data, type = "class")
accuracy_01 <- sum(predictions_01 == test_data$target) / nrow(test_data)
cat("Accuracy for tree_model_01:", accuracy_01, "\n")

# Calculate accuracy for tree_model_02
predictions_02 <- predict(tree_model_02, newdata = test_data, type = "class")
accuracy_02 <- sum(predictions_02 == test_data$target) / nrow(test_data)
cat("Accuracy for tree_model_02:", accuracy_02, "\n")

# Calculate accuracy for tree_model_03
predictions_03 <- predict(tree_model_03, newdata = test_data, type = "class")
accuracy_03 <- sum(predictions_03 == test_data$target) / nrow(test_data)
cat("Accuracy for tree_model_03:", accuracy_03, "\n")

# Calculate accuracy for tree_model_04
predictions_04 <- predict(tree_model_04, newdata = test_data, type = "class")
accuracy_04 <- sum(predictions_04 == test_data$target) / nrow(test_data)
cat("Accuracy for tree_model_04:", accuracy_04, "\n")


```


```{R}

# Calculate precision for tree_model_01
precision_01 <- sum(predictions_01 == "disease" & test_data$target == "disease") / sum(predictions_01 == "disease")
cat("Precision for tree_model_01:", precision_01, "\n")

# Calculate precision for tree_model_02
precision_02 <- sum(predictions_02 == "disease" & test_data$target == "disease") / sum(predictions_02 == "disease")
cat("Precision for tree_model_02:", precision_02, "\n")

# Calculate precision for tree_model_03
precision_03 <- sum(predictions_03 == "disease" & test_data$target == "disease") / sum(predictions_03 == "disease")
cat("Precision for tree_model_03:", precision_03, "\n")

# Calculate precision for tree_model_04
precision_04 <- sum(predictions_04 == "disease" & test_data$target == "disease") / sum(predictions_04 == "disease")
cat("Precision for tree_model_04:", precision_04, "\n")
```

```{r}
# Calculate recall for tree_model_01
recall_01 <- sum(predictions_01 == "disease" & test_data$target == "disease") / sum(test_data$target == "disease")
cat("Recall for tree_model_01:", recall_01, "\n")

# Calculate recall for tree_model_02
recall_02 <- sum(predictions_02 == "disease" & test_data$target == "disease") / sum(test_data$target == "disease")
cat("Recall for tree_model_02:", recall_02, "\n")

# Calculate recall for tree_model_03
recall_03 <- sum(predictions_03 == "disease" & test_data$target == "disease") / sum(test_data$target == "disease")
cat("Recall for tree_model_03:", recall_03, "\n")

# Calculate recall for tree_model_04
recall_04 <- sum(predictions_04 == "disease" & test_data$target == "disease") / sum(test_data$target == "disease")
cat("Recall for tree_model_04:", recall_04, "\n")

```

```{r}

# Calculate F-score for tree_model_01
f_score_01 <- 2 * (precision_01 * recall_01) / (precision_01 + recall_01)
cat("F-score for tree_model_01:", f_score_01, "\n")

# Calculate F-score for tree_model_02
f_score_02 <- 2 * (precision_02 * recall_02) / (precision_02 + recall_02)
cat("F-score for tree_model_02:", f_score_02, "\n")

# Calculate F-score for tree_model_03
f_score_03 <- 2 * (precision_03 * recall_03) / (precision_03 + recall_03)
cat("F-score for tree_model_03:", f_score_03, "\n")

# Calculate F-score for tree_model_04
f_score_04 <- 2 * (precision_04 * recall_04) / (precision_04 + recall_04)
cat("F-score for tree_model_04:", f_score_04, "\n")


```

```{r}

library(caret)

# Make predictions on the test dataset
predictions_01 <- predict(tree_model_01, newdata = test_data, type = "class")
predictions_02 <- predict(tree_model_02, newdata = test_data, type = "class")
predictions_03 <- predict(tree_model_03, newdata = test_data, type = "class")
predictions_04 <- predict(tree_model_04, newdata = test_data, type = "class")

# Calculate confusion matrix for tree_model_01
confusion_matrix_01 <- confusionMatrix(predictions_01, test_data$target)
cat("Confusion Matrix for tree_model_01:\n")
print(confusion_matrix_01)

# Calculate confusion matrix for tree_model_02
confusion_matrix_02 <- confusionMatrix(predictions_02, test_data$target)
cat("Confusion Matrix for tree_model_02:\n")
print(confusion_matrix_02)

# Calculate confusion matrix for tree_model_03
confusion_matrix_03 <- confusionMatrix(predictions_03, test_data$target)
cat("Confusion Matrix for tree_model_03:\n")
print(confusion_matrix_03)

# Calculate confusion matrix for tree_model_04
confusion_matrix_04 <- confusionMatrix(predictions_04, test_data$target)
cat("Confusion Matrix for tree_model_04:\n")
print(confusion_matrix_04)

```

```{r}
calculate_metrics <- function(confusion_matrix) {
  # Calculate accuracy
  accuracy <- confusion_matrix$overall['Accuracy']
  
  # Calculate precision
  precision <- confusion_matrix$byClass['Precision']
  
  # Calculate F-score
  f_score <- confusion_matrix$byClass['F1']
  
  # Return the metrics
  return(list(accuracy = accuracy, precision = precision, f_score = f_score))
}

# Calculate metrics for tree_model_01
metrics_01 <- calculate_metrics(confusion_matrix_01)

# Calculate metrics for tree_model_02
metrics_02 <- calculate_metrics(confusion_matrix_02)

# Calculate metrics for tree_model_03
metrics_03 <- calculate_metrics(confusion_matrix_03)

# Calculate metrics for tree_model_04
metrics_04 <- calculate_metrics(confusion_matrix_04)

# Print the metrics for each model
cat("Metrics for tree_model_01:\n")
print(metrics_01)

cat("Metrics for tree_model_02:\n")
print(metrics_02)

cat("Metrics for tree_model_03:\n")
print(metrics_03)

cat("Metrics for tree_model_04:\n")
print(metrics_04)



accuracy
```

```{r}

library(pROC)


# Assuming your true target values are stored in a vector called "true_labels"
roc_obj_01 <- roc(test_data$target, as.numeric(predictions_01))
auc_value_01 <- auc(roc_obj_01)

auc_value_01


# Assuming your true target values are stored in a vector called "true_labels"
roc_obj_02 <- roc(test_data$target, as.numeric(predictions_02))
auc_value_02 <- auc(roc_obj_02)

auc_value_02


# Assuming your true target values are stored in a vector called "true_labels"
roc_obj_03 <- roc(test_data$target, as.numeric(predictions_03))
auc_value_03 <- auc(roc_obj_01)

auc_value_03


# Assuming your true target values are stored in a vector called "true_labels"
roc_obj_04 <- roc(test_data$target, as.numeric(predictions_04))
auc_value_04 <- auc(roc_obj_04)

auc_value_04

```